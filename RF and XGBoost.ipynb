{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest, XG Boost"
      ],
      "metadata": {
        "id": "Bct7XyxH_wLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load the Excel file\n",
        "nifty50_excel_file = 'combined_stock_data_single_sheet.xlsx'\n",
        "xls = pd.ExcelFile(nifty50_excel_file)\n",
        "\n",
        "# Define features (X)\n",
        "features = ['Open', 'High', 'Low', 'Adj Close', 'Volume',\n",
        "       'Previous_Close', '5SMA', '10SMA', '20SMA', '50SMA', '100SMA', '200SMA',\n",
        "       '5EMA', '10EMA', '20EMA', 'MACD', 'MACD_signal', 'RSI', 'PSAR',\n",
        "       'vortex_indicator', 'Upper_Band', 'Lower_Band', 'ATR5', 'ATR10',\n",
        "       'ATR20', 'ATR50', 'Stoch_Signal', 'Stoch', 'WR', 'TSI', 'ADX', 'VWAP',\n",
        "       'Daily_Return', 'Cumulative_Return', 'ROC5', 'ROC10', 'ROC20', 'ROC50',\n",
        "       'ROC100', 'ROC200', 'CMF', 'Daily_Log_Return']\n",
        "\n",
        "# Create an empty DataFrame to store results\n",
        "all_results_rf = pd.DataFrame(columns=['Company', 'RMSE', 'MSE', 'MAE', 'R-squared', 'MAPE'])\n",
        "all_results_xgb = pd.DataFrame(columns=['Company', 'RMSE', 'MSE', 'MAE', 'R-squared', 'MAPE'])\n",
        "\n",
        "# Number of days ahead to predict\n",
        "days_to_predict = 10\n",
        "\n",
        "# Loop through each sheet (company) in the Excel file\n",
        "for sheet_name in xls.sheet_names:\n",
        "    print(f\"Processing data for {sheet_name}...\")\n",
        "\n",
        "    # Get firm data for the current stock\n",
        "    try:\n",
        "        df = pd.read_excel(nifty50_excel_file, sheet_name=sheet_name)\n",
        "\n",
        "        # Shift the 'Close' column to create the target variable (10 days ahead)\n",
        "        df[f'Close_{days_to_predict}_Days_Ahead'] = df['Close'].shift(-days_to_predict)\n",
        "\n",
        "        # Remove rows with NaN values in the target variable\n",
        "        df = df.dropna(subset=[f'Close_{days_to_predict}_Days_Ahead'])\n",
        "\n",
        "        # Define the target variable (y)\n",
        "        target = f'Close_{days_to_predict}_Days_Ahead'\n",
        "\n",
        "        X = df[features]\n",
        "        y = df[target]\n",
        "\n",
        "        # Split the data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Standardize the features\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Random Forest Hyperparameter Tuning\n",
        "        rf_param_grid = {\n",
        "            'n_estimators': [50, 100, 200],\n",
        "            'max_depth': [None, 10, 20, 30],\n",
        "            'min_samples_split': [2, 5, 10],\n",
        "            'min_samples_leaf': [1, 2, 4]\n",
        "        }\n",
        "\n",
        "        rf_grid_search = GridSearchCV(RandomForestRegressor(random_state=42), rf_param_grid, cv=5, n_jobs=-1)\n",
        "        rf_grid_search.fit(X_train, y_train)\n",
        "        rf_model = rf_grid_search.best_estimator_\n",
        "        rf_y_pred = rf_model.predict(X_test)\n",
        "\n",
        "        # XGBoost Hyperparameter Tuning\n",
        "        xgb_param_dist = {\n",
        "            'n_estimators': [50, 100, 200],\n",
        "            'max_depth': [3, 4, 5, 6],\n",
        "            'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
        "            'subsample': [0.7, 0.8, 0.9, 1.0],\n",
        "            'colsample_bytree': [0.7, 0.8, 0.9, 1.0]\n",
        "        }\n",
        "\n",
        "        xgb_random_search = RandomizedSearchCV(xgb.XGBRegressor(random_state=42), xgb_param_dist, cv=5, n_iter=20, n_jobs=-1)\n",
        "        xgb_random_search.fit(X_train, y_train)\n",
        "        xgb_model = xgb_random_search.best_estimator_\n",
        "        xgb_y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "        # Calculate evaluation metrics for Random Forest\n",
        "        rf_rmse = np.sqrt(mean_squared_error(y_test, rf_y_pred))\n",
        "        rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
        "        rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
        "        rf_r_squared = r2_score(y_test, rf_y_pred)\n",
        "        rf_mape = np.mean(np.abs((y_test.values - rf_y_pred) / y_test.values)) * 100\n",
        "\n",
        "        # Calculate evaluation metrics for XGBoost\n",
        "        xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_y_pred))\n",
        "        xgb_mse = mean_squared_error(y_test, xgb_y_pred)\n",
        "        xgb_mae = mean_absolute_error(y_test, xgb_y_pred)\n",
        "        xgb_r_squared = r2_score(y_test, xgb_y_pred)\n",
        "        xgb_mape = np.mean(np.abs((y_test.values - xgb_y_pred) / y_test.values)) * 100\n",
        "\n",
        "        # Store results in the DataFrames\n",
        "        rf_result = pd.DataFrame({\n",
        "            'Company': [sheet_name],\n",
        "            'RMSE': [rf_rmse],\n",
        "            'MSE': [rf_mse],\n",
        "            'MAE': [rf_mae],\n",
        "            'R-squared': [rf_r_squared],\n",
        "            'MAPE': [rf_mape]\n",
        "        })\n",
        "\n",
        "        xgb_result = pd.DataFrame({\n",
        "            'Company': [sheet_name],\n",
        "            'RMSE': [xgb_rmse],\n",
        "            'MSE': [xgb_mse],\n",
        "            'MAE': [xgb_mae],\n",
        "            'R-squared': [xgb_r_squared],\n",
        "            'MAPE': [xgb_mape]\n",
        "        })\n",
        "\n",
        "        all_results_rf = all_results_rf.append(rf_result, ignore_index=True)\n",
        "        all_results_xgb = all_results_xgb.append(xgb_result, ignore_index=True)\n",
        "\n",
        "        print(f\"Data for {sheet_name} processed.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing data for {sheet_name}: {str(e)}\")\n",
        "\n",
        "# Save the results to CSV files\n",
        "all_results_rf.to_csv('random_forest_results.csv', index=False)\n",
        "all_results_xgb.to_csv('xgboost_results.csv', index=False)\n",
        "\n",
        "print('Results saved to random_forest_results.csv and xgboost_results.csv')\n"
      ],
      "metadata": {
        "id": "zBrWoebQFNVd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}