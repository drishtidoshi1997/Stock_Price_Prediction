{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## RF and XGBOOST"
      ],
      "metadata": {
        "id": "Bct7XyxH_wLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load the Excel file\n",
        "nifty50_excel_file = 'combined_stock_data_single_sheet.xlsx'\n",
        "xls = pd.ExcelFile(nifty50_excel_file)\n",
        "\n",
        "# Define features (X)\n",
        "features = ['Open', 'High', 'Low', 'Adj Close', 'Volume',\n",
        "            'Previous_Close', '5SMA', '10SMA', '20SMA', '50SMA', '100SMA', '200SMA',\n",
        "            '5EMA', '10EMA', '20EMA', 'MACD', 'MACD_signal', 'RSI', 'PSAR',\n",
        "            'vortex_indicator', 'Upper_Band', 'Lower_Band', 'ATR5', 'ATR10',\n",
        "            'ATR20', 'ATR50', 'Stoch_Signal', 'Stoch', 'WR', 'TSI', 'ADX', 'VWAP',\n",
        "            'Daily_Return', 'Cumulative_Return', 'ROC5', 'ROC10', 'ROC20', 'ROC50',\n",
        "            'ROC100', 'ROC200', 'CMF', 'Daily_Log_Return']\n",
        "\n",
        "# Create an empty DataFrame to store results\n",
        "all_results_rf = pd.DataFrame(columns=['Company', 'RMSE', 'MSE', 'MAE', 'R-squared', 'MAPE'])\n",
        "all_results_gb = pd.DataFrame(columns=['Company', 'RMSE', 'MSE', 'MAE', 'R-squared', 'MAPE'])\n",
        "all_results_xgb = pd.DataFrame(columns=['Company', 'RMSE', 'MSE', 'MAE', 'R-squared', 'MAPE'])\n",
        "\n",
        "# Number of days ahead to predict\n",
        "days_to_predict = 10\n",
        "\n",
        "# Loop through each sheet (company) in the Excel file\n",
        "for sheet_name in xls.sheet_names:\n",
        "    print(f\"Processing data for {sheet_name}...\")\n",
        "\n",
        "    # Get firm data for the current stock\n",
        "    try:\n",
        "        df = pd.read_excel(nifty50_excel_file, sheet_name=sheet_name)\n",
        "\n",
        "        # Shift the 'Close' column to create the target variable (10 days ahead)\n",
        "        df[f'Close_{days_to_predict}_Days_Ahead'] = df['Close'].shift(-days_to_predict)\n",
        "\n",
        "        # Remove rows with NaN values in the target variable\n",
        "        df = df.dropna(subset=[f'Close_{days_to_predict}_Days_Ahead'])\n",
        "\n",
        "        # Define the target variable (y)\n",
        "        target = f'Close_{days_to_predict}_Days_Ahead'\n",
        "\n",
        "        X = df[features]\n",
        "        y = df[target]\n",
        "\n",
        "        # Split the data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Standardize the features\n",
        "        scaler = StandardScaler()\n",
        "        X_train = scaler.fit_transform(X_train)\n",
        "        X_test = scaler.transform(X_test)\n",
        "\n",
        "        # Create a Random Forest Regressor model with complex hyperparameters\n",
        "        rf_model = RandomForestRegressor(n_estimators=200, max_depth=20, min_samples_split=5, min_samples_leaf=2, random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        rf_model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict the target variable on the test data\n",
        "        rf_y_pred = rf_model.predict(X_test)\n",
        "\n",
        "        # Create a Gradient Boosting Regressor model with complex hyperparameters\n",
        "        gb_model = GradientBoostingRegressor(n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        gb_model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict the target variable on the test data\n",
        "        gb_y_pred = gb_model.predict(X_test)\n",
        "\n",
        "        # Create an XGBoost Regressor model with complex hyperparameters\n",
        "        xgb_model = xgb.XGBRegressor(n_estimators=200, max_depth=6, learning_rate=0.2, subsample=0.9, colsample_bytree=0.8, random_state=42)\n",
        "\n",
        "        # Train the model\n",
        "        xgb_model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict the target variable on the test data\n",
        "        xgb_y_pred = xgb_model.predict(X_test)\n",
        "\n",
        "        # Calculate evaluation metrics for Random Forest\n",
        "        rf_rmse = np.sqrt(mean_squared_error(y_test, rf_y_pred))\n",
        "        rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
        "        rf_mae = mean_absolute_error(y_test, rf_y_pred)\n",
        "        rf_r_squared = r2_score(y_test, rf_y_pred)\n",
        "        rf_mape = np.mean(np.abs((y_test.values - rf_y_pred) / y_test.values)) * 100\n",
        "\n",
        "        # Calculate evaluation metrics for Gradient Boosting\n",
        "        gb_rmse = np.sqrt(mean_squared_error(y_test, gb_y_pred))\n",
        "        gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
        "        gb_mae = mean_absolute_error(y_test, gb_y_pred)\n",
        "        gb_r_squared = r2_score(y_test, gb_y_pred)\n",
        "        gb_mape = np.mean(np.abs((y_test.values - gb_y_pred) / y_test.values)) * 100\n",
        "\n",
        "        # Calculate evaluation metrics for XGBoost\n",
        "        xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_y_pred))\n",
        "        xgb_mse = mean_squared_error(y_test, xgb_y_pred)\n",
        "        xgb_mae = mean_absolute_error(y_test, xgb_y_pred)\n",
        "        xgb_r_squared = r2_score(y_test, xgb_y_pred)\n",
        "        xgb_mape = np.mean(np.abs((y_test.values - xgb_y_pred) / y_test.values)) * 100\n",
        "\n",
        "        # Store results in the DataFrames\n",
        "        rf_result = pd.DataFrame({\n",
        "            'Company': [sheet_name],\n",
        "            'RMSE': [rf_rmse],\n",
        "            'MSE': [rf_mse],\n",
        "            'MAE': [rf_mae],\n",
        "            'R-squared': [rf_r_squared],\n",
        "            'MAPE': [rf_mape]\n",
        "        })\n",
        "\n",
        "        gb_result = pd.DataFrame({\n",
        "            'Company': [sheet_name],\n",
        "            'RMSE': [gb_rmse],\n",
        "            'MSE': [gb_mse],\n",
        "            'MAE': [gb_mae],\n",
        "            'R-squared': [gb_r_squared],\n",
        "            'MAPE': [gb_mape]\n",
        "        })\n",
        "\n",
        "        xgb_result = pd.DataFrame({\n",
        "            'Company': [sheet_name],\n",
        "            'RMSE': [xgb_rmse],\n",
        "            'MSE': [xgb_mse],\n",
        "            'MAE': [xgb_mae],\n",
        "            'R-squared': [xgb_r_squared],\n",
        "            'MAPE': [xgb_mape]\n",
        "        })\n",
        "\n",
        "        all_results_rf = all_results_rf.append(rf_result, ignore_index=True)\n",
        "        all_results_gb = all_results_gb.append(gb_result, ignore_index=True)\n",
        "        all_results_xgb = all_results_xgb.append(xgb_result, ignore_index=True)\n",
        "\n",
        "        print(f\"Data for {sheet_name} processed.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing data for {sheet_name}: {str(e)}\")\n",
        "\n",
        "# Save the results to CSV files\n",
        "all_results_rf.to_csv('random_forest_results.csv', index=False)\n",
        "all_results_gb.to_csv('gradient_boosting_results.csv', index=False)\n",
        "all_results_xgb.to_csv('xgboost_results.csv', index=False)\n",
        "\n",
        "print('Results saved to random_forest_results.csv, gradient_boosting_results.csv, and xgboost_results.csv')\n"
      ],
      "metadata": {
        "id": "mrWW1L0rbP45"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}